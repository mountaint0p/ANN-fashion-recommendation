{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv(\"./split-data/train_new.csv\")\n",
    "test_df = pd.read_csv(\"./split-data/test_new.csv\")\n",
    "val_df = pd.read_csv(\"./split-data/val_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease the validation set size so there are at most 100 images in each category\n",
    "val_df = val_df.groupby('category').head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15889 validated image filenames belonging to 46 classes.\n",
      "Found 3139 validated image filenames belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create the image data generators\n",
    "traingen=ImageDataGenerator(rescale= 1./255)\n",
    "train_generator=traingen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"./dataset\",\n",
    "    x_col=\"img_path\",\n",
    "    y_col= \"category\",\n",
    "    batch_size=64,\n",
    "    shuffle= True,\n",
    "    target_size = (256,256),\n",
    "    class_mode=\"categorical\",\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "# Create the validation data generator\n",
    "valgen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = valgen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=\"./dataset\",\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"category\",\n",
    "    target_size=(256, 256),\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\",\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.applications.densenet import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained DenseNet121 model\n",
    "# Make classifer deeper\n",
    "# Add new features (dropout, etc)\n",
    "# Make more layers trainable (last 1-2)\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))\n",
    "for i in range(0, len(base_model.layers) - 2):\n",
    "    base_model.layers[i].trainable = False\n",
    "\n",
    "# Create new model\n",
    "num_classes = 46\n",
    "layer1 = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(base_model.output)\n",
    "dropout1 = Dropout(0.5)(layer1)\n",
    "layer2 = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(dropout1)\n",
    "dropout2 = Dropout(0.5)(layer2)\n",
    "output = Dense(num_classes, activation='softmax')(dropout2)\n",
    "model = Model(inputs=base_model.inputs, outputs=output)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 04:23:12.832907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - ETA: 0s - loss: 4.6150 - accuracy: 0.0746 - top_k_categorical_accuracy: 0.2767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 04:36:08.617317: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 947s 4s/step - loss: 4.6150 - accuracy: 0.0746 - top_k_categorical_accuracy: 0.2767 - val_loss: 3.9547 - val_accuracy: 0.2424 - val_top_k_categorical_accuracy: 0.6234 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "249/249 [==============================] - 996s 4s/step - loss: 3.8641 - accuracy: 0.1636 - top_k_categorical_accuracy: 0.5087 - val_loss: 3.3998 - val_accuracy: 0.3135 - val_top_k_categorical_accuracy: 0.6878 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "249/249 [==============================] - 994s 4s/step - loss: 3.5106 - accuracy: 0.2210 - top_k_categorical_accuracy: 0.6087 - val_loss: 3.1492 - val_accuracy: 0.3393 - val_top_k_categorical_accuracy: 0.7235 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "249/249 [==============================] - 1009s 4s/step - loss: 3.3003 - accuracy: 0.2639 - top_k_categorical_accuracy: 0.6527 - val_loss: 3.0102 - val_accuracy: 0.3514 - val_top_k_categorical_accuracy: 0.7397 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "249/249 [==============================] - 1004s 4s/step - loss: 3.1547 - accuracy: 0.2888 - top_k_categorical_accuracy: 0.6840 - val_loss: 2.9115 - val_accuracy: 0.3549 - val_top_k_categorical_accuracy: 0.7486 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "249/249 [==============================] - 997s 4s/step - loss: 3.0529 - accuracy: 0.3021 - top_k_categorical_accuracy: 0.7034 - val_loss: 2.8396 - val_accuracy: 0.3692 - val_top_k_categorical_accuracy: 0.7569 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "249/249 [==============================] - 1028s 4s/step - loss: 2.9697 - accuracy: 0.3212 - top_k_categorical_accuracy: 0.7211 - val_loss: 2.7795 - val_accuracy: 0.3762 - val_top_k_categorical_accuracy: 0.7646 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "249/249 [==============================] - 1010s 4s/step - loss: 2.9025 - accuracy: 0.3381 - top_k_categorical_accuracy: 0.7331 - val_loss: 2.7237 - val_accuracy: 0.3877 - val_top_k_categorical_accuracy: 0.7700 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "249/249 [==============================] - 993s 4s/step - loss: 2.8393 - accuracy: 0.3445 - top_k_categorical_accuracy: 0.7412 - val_loss: 2.6792 - val_accuracy: 0.3915 - val_top_k_categorical_accuracy: 0.7776 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "249/249 [==============================] - 993s 4s/step - loss: 2.7760 - accuracy: 0.3570 - top_k_categorical_accuracy: 0.7577 - val_loss: 2.6406 - val_accuracy: 0.3973 - val_top_k_categorical_accuracy: 0.7827 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "249/249 [==============================] - 1000s 4s/step - loss: 2.7294 - accuracy: 0.3650 - top_k_categorical_accuracy: 0.7669 - val_loss: 2.6186 - val_accuracy: 0.3976 - val_top_k_categorical_accuracy: 0.7881 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "249/249 [==============================] - 1012s 4s/step - loss: 2.6876 - accuracy: 0.3760 - top_k_categorical_accuracy: 0.7714 - val_loss: 2.5802 - val_accuracy: 0.3998 - val_top_k_categorical_accuracy: 0.7913 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "249/249 [==============================] - 1020s 4s/step - loss: 2.6341 - accuracy: 0.3862 - top_k_categorical_accuracy: 0.7764 - val_loss: 2.5543 - val_accuracy: 0.4052 - val_top_k_categorical_accuracy: 0.7968 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "249/249 [==============================] - 1023s 4s/step - loss: 2.5982 - accuracy: 0.3915 - top_k_categorical_accuracy: 0.7823 - val_loss: 2.5303 - val_accuracy: 0.3985 - val_top_k_categorical_accuracy: 0.7952 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "249/249 [==============================] - 1018s 4s/step - loss: 2.5560 - accuracy: 0.4056 - top_k_categorical_accuracy: 0.7897 - val_loss: 2.5003 - val_accuracy: 0.4059 - val_top_k_categorical_accuracy: 0.8022 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "249/249 [==============================] - 1018s 4s/step - loss: 2.5397 - accuracy: 0.4013 - top_k_categorical_accuracy: 0.7882 - val_loss: 2.4888 - val_accuracy: 0.4154 - val_top_k_categorical_accuracy: 0.8038 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "249/249 [==============================] - 1012s 4s/step - loss: 2.4935 - accuracy: 0.4110 - top_k_categorical_accuracy: 0.8012 - val_loss: 2.4655 - val_accuracy: 0.4192 - val_top_k_categorical_accuracy: 0.8047 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "249/249 [==============================] - 1000s 4s/step - loss: 2.4667 - accuracy: 0.4185 - top_k_categorical_accuracy: 0.8003 - val_loss: 2.4525 - val_accuracy: 0.4221 - val_top_k_categorical_accuracy: 0.8050 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "249/249 [==============================] - 985s 4s/step - loss: 2.4357 - accuracy: 0.4292 - top_k_categorical_accuracy: 0.8077 - val_loss: 2.4366 - val_accuracy: 0.4196 - val_top_k_categorical_accuracy: 0.8066 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "249/249 [==============================] - 974s 4s/step - loss: 2.4065 - accuracy: 0.4281 - top_k_categorical_accuracy: 0.8138 - val_loss: 2.4125 - val_accuracy: 0.4199 - val_top_k_categorical_accuracy: 0.8108 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    ")\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to a file\n",
    "model.save(\"./model-data/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from a file\n",
    "from keras.models import load_model\n",
    "model = load_model(\"./model-data/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10904 validated image filenames belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "testgen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = testgen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=\"./dataset\",\n",
    "    x_col=\"img_path\",\n",
    "    y_col=\"category\",\n",
    "    target_size=(256, 256),\n",
    "    batch_size=128,\n",
    "    class_mode=\"categorical\",\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 01:02:00.591244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 511s 6s/step - loss: 2.4536 - accuracy: 0.4062 - top_k_categorical_accuracy: 0.8110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4535539150238037, 0.4061812162399292, 0.8109868168830872]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model on the first batch of test data\n",
    "model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
